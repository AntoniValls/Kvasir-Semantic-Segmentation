{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6ad9121-d295-4262-95d6-6bafb6a6ea24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd86e08a-1793-417a-adb0-a7d393d96de9",
   "metadata": {
    "id": "n6MrmYKPOPHQ"
   },
   "source": [
    "Lets dynamically choose type of device to use for our computations. To run on your own GPU one needs to install pytorch and cuda-toolkit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9c012de-19ac-4e63-a310-128891217c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5a98662-e156-4ebb-984a-f57102ced797",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3ooJw43yONE2",
    "outputId": "afe428b8-b6b9-404f-9a21-b8175e5aeb7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb2f9bc2-d877-4384-a1c1-64557b083917",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "No CUDA GPUs are available",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_device_properties\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/CV/Kvasir-Semantic-Segmentation/.venv/lib/python3.10/site-packages/torch/cuda/__init__.py:444\u001b[0m, in \u001b[0;36mget_device_properties\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_device_properties\u001b[39m(device: _device_t) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _CudaDeviceProperties:\n\u001b[1;32m    435\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Get the properties of a device.\u001b[39;00m\n\u001b[1;32m    436\u001b[0m \n\u001b[1;32m    437\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;124;03m        _CudaDeviceProperties: the properties of the device\u001b[39;00m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 444\u001b[0m     \u001b[43m_lazy_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# will define _get_device_properties\u001b[39;00m\n\u001b[1;32m    445\u001b[0m     device \u001b[38;5;241m=\u001b[39m _get_device_index(device, optional\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    446\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m device \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m device_count():\n",
      "File \u001b[0;32m~/CV/Kvasir-Semantic-Segmentation/.venv/lib/python3.10/site-packages/torch/cuda/__init__.py:293\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron:\n\u001b[1;32m    292\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLAZY\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 293\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[1;32m    297\u001b[0m _tls\u001b[38;5;241m.\u001b[39mis_initializing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No CUDA GPUs are available"
     ]
    }
   ],
   "source": [
    "torch.cuda.get_device_properties(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a44df4-7501-4d28-9480-3717d3565b00",
   "metadata": {},
   "source": [
    "Define the seed for reproductivity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b6355a90-bdb9-4082-b08b-2eff47aa47db",
   "metadata": {
    "id": "5iDI_mz8N1qn"
   },
   "outputs": [],
   "source": [
    "def set_seed(seed, use_gpu = True):\n",
    "    \"\"\"\n",
    "    Set SEED for PyTorch reproducibility\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if use_gpu:\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "SEED = 196\n",
    "USE_SEED = True\n",
    "if USE_SEED:\n",
    "    set_seed(SEED, torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857f3e65-9609-4d0b-acd0-e0a8cd4370c5",
   "metadata": {},
   "source": [
    "**Load the images and masks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d1a0c63-4849-4005-b580-278ec239e866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with data augmentation\n",
    "images = np.load(\"data/augmented/combined_images.npy\")\n",
    "masks = np.load(\"data/augmented/combined_masks.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fd9f0b16-f205-4757-a8f8-efb5c9c241cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 256, 3)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masks[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3649f6c4-34cc-4535-8b9a-4bb5ee4c8792",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(threshold=np.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b70f27-7d8e-410a-9d18-320d15d0f090",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "56c514a3-ff1d-4c00-b692-69f59cca7297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "result = (masks[0][:,:,0] == masks[0][:,:,1]) & (masks[0][:,:,1] == masks[0][:,:,2])\n",
    "\n",
    "# Alternatively, using numpy logical_and\n",
    "result = np.logical_and(masks[0][:,:,0] == masks[0][:,:,1], masks[0][:,:,1] == masks[0][:,:,2])\n",
    "\n",
    "# The result will be a boolean array of shape (256, 256) indicating where the condition is true\n",
    "print(result.all())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1d2d28-a3f3-42f4-b969-408739eb8058",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "08a820ae-0476-4fe1-8d80-d313a3b6e978",
   "metadata": {},
   "outputs": [
    {
     "ename": "AxisError",
     "evalue": "axis 1 is out of bounds for array of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m np\u001b[38;5;241m.\u001b[39mmax(masks[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mshape, axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\VisionProj\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:2810\u001b[0m, in \u001b[0;36mmax\u001b[1;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m   2692\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_max_dispatcher)\n\u001b[0;32m   2693\u001b[0m \u001b[38;5;129m@set_module\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   2694\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmax\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue, initial\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue,\n\u001b[0;32m   2695\u001b[0m          where\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue):\n\u001b[0;32m   2696\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2697\u001b[0m \u001b[38;5;124;03m    Return the maximum of an array or maximum along an axis.\u001b[39;00m\n\u001b[0;32m   2698\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2808\u001b[0m \u001b[38;5;124;03m    5\u001b[39;00m\n\u001b[0;32m   2809\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2810\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapreduction(a, np\u001b[38;5;241m.\u001b[39mmaximum, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m, axis, \u001b[38;5;28;01mNone\u001b[39;00m, out,\n\u001b[0;32m   2811\u001b[0m                           keepdims\u001b[38;5;241m=\u001b[39mkeepdims, initial\u001b[38;5;241m=\u001b[39minitial, where\u001b[38;5;241m=\u001b[39mwhere)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\VisionProj\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:88\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[1;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     86\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m reduction(axis\u001b[38;5;241m=\u001b[39maxis, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpasskwargs)\n\u001b[1;32m---> 88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ufunc\u001b[38;5;241m.\u001b[39mreduce(obj, axis, dtype, out, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpasskwargs)\n",
      "\u001b[1;31mAxisError\u001b[0m: axis 1 is out of bounds for array of dimension 1"
     ]
    }
   ],
   "source": [
    "np.max(masks[1].shape, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240df45e-47c8-43d8-98ab-a9ce2f5c6ece",
   "metadata": {},
   "source": [
    "**Standaritzation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3086adf4-db6d-48d1-9f9d-59e998ebad47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----  NORMALIZATION VALUES  -----\n",
      "Mean (RGB): [0.56399276 0.33202926 0.2465689 ]\n",
      "Standard Deviation (RGB): [0.3123053  0.23121322 0.19635625]\n"
     ]
    }
   ],
   "source": [
    "mean = np.mean(images, axis = (0,1,2)) / 255\n",
    "std = np.std(images, axis = (0,1,2)) / 255\n",
    "\n",
    "print(\"-----  NORMALIZATION VALUES  -----\")\n",
    "print(f\"Mean (RGB): {mean}\")\n",
    "print(f\"Standard Deviation (RGB): {std}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "12a4490c-8028-43ba-a7e3-2c3d0c5ba29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "transforms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),  # Convert the image to a PyTorch tensor and normalize it between [0, 1]\n",
    "    torchvision.transforms.Normalize(mean, std)  # Normalize the tensor using the provided mean and standard deviation\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17873df3-f032-400a-9466-52065b2e3098",
   "metadata": {
    "id": "cMD4Zi_7LIex"
   },
   "source": [
    "**Data splitting**\n",
    "\n",
    "\n",
    "\n",
    "*   Train-test split (70/30)\n",
    "*   Train-validation split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1f43c959-4947-43bb-8f5d-b983a7a06c58",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4d-UOLrs9mQt",
    "outputId": "dcf80fa4-e950-4a8d-8b23-420138e8e386"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train images shape: (2800, 256, 256, 3)\n",
      "Test images shape: (1200, 256, 256, 3)\n",
      "Train masks shape: (2800, 256, 256, 3)\n",
      "Test masks shape: (1200, 256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the dataset into train and test sets\n",
    "train_images, test_images, train_masks, test_masks = train_test_split(\n",
    "    images, masks, test_size=0.3, random_state=42)\n",
    "\n",
    "# Print the shapes of the train and test sets\n",
    "print(\"Train images shape:\", train_images.shape)\n",
    "print(\"Test images shape:\", test_images.shape)\n",
    "print(\"Train masks shape:\", train_masks.shape)\n",
    "print(\"Test masks shape:\", test_masks.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3be31073-1bd1-4ddd-8c25-97d7a83904db",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3bY2e4kp_9BR",
    "outputId": "350540c0-b2dc-4464-df8c-5579b72f3391"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Images Shape: (2520, 256, 256, 3)\n",
      "Training Masks Shape: (2520, 256, 256, 3)\n",
      "Validation Images Shape: (280, 256, 256, 3)\n",
      "Validation Masks Shape: (280, 256, 256, 3)\n",
      "Number of Training Examples: 2520\n",
      "Number of Validation Examples: 280\n"
     ]
    }
   ],
   "source": [
    "#Validation set (10%)\n",
    "training_images, val_images, training_masks, val_masks = train_test_split(\n",
    "    train_images, train_masks, test_size=0.1, random_state=42)\n",
    "# Check shape of training images and masks\n",
    "print(\"Training Images Shape:\", training_images.shape)\n",
    "print(\"Training Masks Shape:\", training_masks.shape)\n",
    "\n",
    "# Check shape of validation images and masks\n",
    "print(\"Validation Images Shape:\", val_images.shape)\n",
    "print(\"Validation Masks Shape:\", val_masks.shape)\n",
    "\n",
    "# Check length of training and validation sets\n",
    "print(\"Number of Training Examples:\", len(training_images))\n",
    "print(\"Number of Validation Examples:\", len(val_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aee261a9-8a27-4a41-9ec7-dbdbfd44bda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.preprocess import KvasirDataset\n",
    "\n",
    "# Create KvasirDataset objects for train, validation and test sets\n",
    "train_dataset = KvasirDataset(images=train_images, masks=train_masks, transforms=transforms)\n",
    "val_dataset = KvasirDataset(images=val_images,masks=val_masks, transforms=transforms)\n",
    "test_dataset = KvasirDataset(images=test_images, masks=test_masks, transforms=transforms) # not sure about transforms in test set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12686a1a-38e0-438f-9ebb-a7f65621a91d",
   "metadata": {},
   "source": [
    "**Define the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a9b7ac48-738c-47c7-8de4-235b5d8b5c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {}\n",
    "config['name']='First_try'\n",
    "config['epochs']=10\n",
    "config['batch_size']=64\n",
    "\n",
    "config['arch']='NestedUNet'\n",
    "config['deep_supervision']=True\n",
    "config['input_channels']=3\n",
    "config['num_classes']=1\n",
    "config['early_stopping']=5 # 5 epochs without improving the dice coefficient\n",
    "#config['input_w']=128\n",
    "#config['input_h']=128\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8c60e0c8-abc1-448f-bf64-48ba5797c66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_iterator = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True)\n",
    "test_iterator = DataLoader(test_dataset, batch_size=config['batch_size'])\n",
    "val_iterator = DataLoader(val_dataset,batch_size=config['batch_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f1d69ed0-90ca-41ed-a570-fd85590f4d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 9,279,396 trainable parameters.\n"
     ]
    }
   ],
   "source": [
    "from src.main import NestedUNet\n",
    "from src.utils import count_parameters\n",
    "\n",
    "model = NestedUNet(config)\n",
    "print(f\"The model has {count_parameters(model):,} trainable parameters.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3f5002af-adc9-466d-8710-bb026e56c2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a8f28d1f-e1d9-43d9-a984-d8a924ad734d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.loss import BCEDiceLoss\n",
    "import torch.optim as optim\n",
    "\n",
    "criterion = BCEDiceLoss().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4) #TODO apply a scheduler lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a209d906-894a-475f-86c5-3770c872d67a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/44 [00:00<?, ?it/s]C:\\Users\\toniv\\anaconda3\\envs\\VisionProj\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 2.25 GiB. GPU  (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\cudnn\\Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 256.00 MiB. GPU ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch [\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (epoch, config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# train for one epoch\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m train_log \u001b[38;5;241m=\u001b[39m train(config, model, train_iterator, criterion, optimizer, config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdeep_supervision\u001b[39m\u001b[38;5;124m'\u001b[39m], device)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# evaluate on validation set\u001b[39;00m\n\u001b[0;32m     23\u001b[0m val_log \u001b[38;5;241m=\u001b[39m evaluate(config, model, val_iterator, criterion, config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdeep_supervision\u001b[39m\u001b[38;5;124m'\u001b[39m], device)\n",
      "File \u001b[1;32m~\\Documents\\Universitat\\UNIPD\\3r Semestre\\Vision and Cognitive Systems\\Project2\\src\\train_val_test.py:37\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(config, model, iterator, criterion, optimizer, deep_supervision, device)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Deep supervision application\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m deep_supervision:\n\u001b[1;32m---> 37\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m     38\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m outputs:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\VisionProj\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\VisionProj\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\Documents\\Universitat\\UNIPD\\3r Semestre\\Vision and Cognitive Systems\\Project2\\src\\main.py:110\u001b[0m, in \u001b[0;36mNestedUNet.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    107\u001b[0m x0_1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv0_1(torch\u001b[38;5;241m.\u001b[39mcat([x0_0, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mup(x1_0)], \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m    109\u001b[0m x2_0 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2_0(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool(x1_0))\n\u001b[1;32m--> 110\u001b[0m x1_1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1_1(torch\u001b[38;5;241m.\u001b[39mcat([x1_0, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mup(x2_0)], \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m    111\u001b[0m x0_2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv0_2(torch\u001b[38;5;241m.\u001b[39mcat([x0_0, x0_1, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mup(x1_1)], \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m    113\u001b[0m x3_0 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv3_0(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool(x2_0))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\VisionProj\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\VisionProj\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\Documents\\Universitat\\UNIPD\\3r Semestre\\Vision and Cognitive Systems\\Project2\\src\\main.py:54\u001b[0m, in \u001b[0;36mVGGBlock.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     51\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(out)\n\u001b[0;32m     52\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(out)\n\u001b[1;32m---> 54\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(out)\n\u001b[0;32m     55\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn2(out)\n\u001b[0;32m     56\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(out)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\VisionProj\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\VisionProj\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\VisionProj\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conv_forward(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\VisionProj\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\u001b[38;5;28minput\u001b[39m, weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    457\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 256.00 MiB. GPU "
     ]
    }
   ],
   "source": [
    "from src.train_val_test import train, evaluate\n",
    "from collections import OrderedDict\n",
    "\n",
    "log = OrderedDict([\n",
    "    ('epoch', []),\n",
    "    ('lr', []),\n",
    "    ('loss', []),\n",
    "    ('iou', []),\n",
    "    ('dice',[]),\n",
    "    ('val_loss', []),\n",
    "    ('val_iou', []),\n",
    "    ('val_dice',[])\n",
    "])\n",
    "\n",
    "best_dice = 0\n",
    "trigger = 0\n",
    "for epoch in range(config['epochs']):\n",
    "    print('Epoch [%d/%d]' % (epoch, config['epochs']))\n",
    "\n",
    "    # train for one epoch\n",
    "    train_log = train(config, model, train_iterator, criterion, optimizer, config['deep_supervision'], device)\n",
    "    # evaluate on validation set\n",
    "    val_log = evaluate(config, model, val_iterator, criterion, config['deep_supervision'], device)\n",
    "\n",
    "    print('loss %.4f - iou %.4f - dice %.4f - val_loss %.4f - val_iou %.4f - val_dice %.4f'\n",
    "          % (train_log['loss'], train_log['iou'], train_log['dice_coef'],val_log['loss'], val_log['iou'], val_log['dice_coef']))\n",
    "\n",
    "    log['epoch'].append(epoch)\n",
    "    log['lr'].append(config['lr'])\n",
    "    log['loss'].append(train_log['loss'])\n",
    "    log['iou'].append(train_log['iou'])\n",
    "    log['dice'].append(train_log['dice_coef'])\n",
    "    log['val_loss'].append(val_log['loss'])\n",
    "    log['val_iou'].append(val_log['iou'])\n",
    "    log['val_dice'].append(val_log['dice_coef'])\n",
    "    \n",
    "    pd.DataFrame(log).to_csv('models/%s/log.csv' %\n",
    "                             config['name'], index=False)\n",
    "\n",
    "    trigger += 1\n",
    "\n",
    "    if val_log['dice_coef'] > best_dice:\n",
    "        torch.save(model.state_dict(), 'models/%s/model.pth' %\n",
    "                   config['name'])\n",
    "        best_dice = val_log['dice_coef']\n",
    "        print(\"=> saved best model\")\n",
    "        trigger = 0\n",
    "\n",
    "    # early stopping\n",
    "    if config['early_stopping'] >= 0 and trigger >= config['early_stopping']:\n",
    "        print(\"=> early stopping\")\n",
    "        break\n",
    "\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc90165-8a81-4977-a747-d67b9ed79bb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
